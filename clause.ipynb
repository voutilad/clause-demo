{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31534f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4c12c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e2babee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Created OpenAI client.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "print(\"> Created OpenAI client.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f99d3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "Score how close the reference answer is to the model answer. You will be comparing these two as JSON objects that\n",
    "contain 2 keys, \"extracted_text\" and \"clause_type\". Score 1.0 if they are both the same, 0.5 if one is the same,\n",
    "and 0.0 if neither are the same.\n",
    "\n",
    "Return just a floating point score in the form of JSON with a score field containing the resulting score\n",
    "and a justification field containing an explanation for the score.\n",
    "\"\"\".strip()\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Reference answer: {\"extracted_text\": {{item.extracted_text}}, \"clause_type\": {{item.clause_type}}}\n",
    "\n",
    "Model answer: {{sample.output_json}}\n",
    "\"\"\".strip()\n",
    "\n",
    "GRADER = {\n",
    "    \"name\": \"Score Model Grader\",\n",
    "    \"type\": \"score_model\",\n",
    "    \"model\": \"o3-mini\",\n",
    "    \"input\": [\n",
    "        {\"role\": \"developer\", \"content\": PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "    ],\n",
    "    \"range\": [0.0, 1.0],\n",
    "    \"pass_threshold\": 0.5,\n",
    "}\n",
    "\n",
    "SCHEMA = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"contract_clause\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"clause_type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The type of contract clause\",\n",
    "                    \"enum\": [\"Exclusivity\", \"Non-Compete\"],\n",
    "                },\n",
    "                \"extracted_text\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The extracted text of the contract clause\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"clause_type\", \"extracted_text\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0cb2506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> created files file-29d025cf762d4836be540750822487e2 and file-541a4f941ad54c1f88c33c252ccbc5de\n"
     ]
    }
   ],
   "source": [
    "with open(\"./clause_matching_training.jsonl\", mode=\"rb\") as f:\n",
    "    training_file = client.files.create(file=f, purpose=\"fine-tune\")\n",
    "    training_file = client.files.wait_for_processing(training_file.id)\n",
    "\n",
    "with open(\"./clause_matching_validation.jsonl\", mode=\"rb\") as f:\n",
    "    validation_file = client.files.create(file=f, purpose=\"fine-tune\")\n",
    "    validation_file = client.files.wait_for_processing(validation_file.id)\n",
    "\n",
    "print(f\"> created files {training_file.id} and {validation_file.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff1eba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Created RFT job ftjob-7a91a676e1fd4b459c367ef55c80d9d1\n",
      "{\n",
      "  \"id\": \"ftjob-7a91a676e1fd4b459c367ef55c80d9d1\",\n",
      "  \"created_at\": 1762909806,\n",
      "  \"model\": \"gpt-5-2025-08-07\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"seed\": 538142950,\n",
      "  \"status\": \"pending\",\n",
      "  \"training_file\": \"file-29d025cf762d4836be540750822487e2\",\n",
      "  \"validation_file\": \"file-541a4f941ad54c1f88c33c252ccbc5de\",\n",
      "  \"estimated_finish\": 1763039106,\n",
      "  \"method\": {\n",
      "    \"type\": \"reinforcement\",\n",
      "    \"reinforcement\": {\n",
      "      \"grader\": {\n",
      "        \"input\": [\n",
      "          {\n",
      "            \"content\": \"Score how close the reference answer is to the model answer. You will be comparing these two as JSON objects that\\ncontain 2 keys, \\\"extracted_text\\\" and \\\"clause_type\\\". Score 1.0 if they are both the same, 0.5 if one is the same,\\nand 0.0 if neither are the same.\\n\\nReturn just a floating point score in the form of JSON with a score field containing the resulting score\\nand a justification field containing an explanation for the score.\",\n",
      "            \"role\": \"developer\"\n",
      "          },\n",
      "          {\n",
      "            \"content\": \"Reference answer: {\\\"extracted_text\\\": {{item.extracted_text}}, \\\"clause_type\\\": {{item.clause_type}}}\\n\\nModel answer: {{sample.output_json}}\",\n",
      "            \"role\": \"user\"\n",
      "          }\n",
      "        ],\n",
      "        \"model\": \"o3-mini\",\n",
      "        \"name\": \"Score Model Grader\",\n",
      "        \"type\": \"score_model\",\n",
      "        \"range\": [\n",
      "          0.0,\n",
      "          1.0\n",
      "        ],\n",
      "        \"pass_threshold\": 0.5\n",
      "      },\n",
      "      \"hyperparameters\": {\n",
      "        \"batch_size\": -1,\n",
      "        \"compute_multiplier\": 1.0,\n",
      "        \"eval_interval\": 5,\n",
      "        \"eval_samples\": 1,\n",
      "        \"learning_rate_multiplier\": 2.0,\n",
      "        \"n_epochs\": -1\n",
      "      },\n",
      "      \"response_format\": {\n",
      "        \"type\": \"json_schema\",\n",
      "        \"json_schema\": {\n",
      "          \"name\": \"contract_clause\",\n",
      "          \"strict\": true,\n",
      "          \"schema\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "              \"clause_type\": {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"The type of contract clause\",\n",
      "                \"enum\": [\n",
      "                  \"Exclusivity\",\n",
      "                  \"Non-Compete\"\n",
      "                ]\n",
      "              },\n",
      "              \"extracted_text\": {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"The extracted text of the contract clause\"\n",
      "              }\n",
      "            },\n",
      "            \"required\": [\n",
      "              \"clause_type\",\n",
      "              \"extracted_text\"\n",
      "            ],\n",
      "            \"additionalProperties\": false\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"additionalParameters\": {\n",
      "    \"completionOverride\": \"True\"\n",
      "  },\n",
      "  \"suffix\": \"dv-clause-test\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job = client.fine_tuning.jobs.create(\n",
    "    suffix=\"dv-clause-test\",\n",
    "    model=\"gpt-5-2025-08-07\",\n",
    "    training_file=training_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    method={\n",
    "        \"type\": \"reinforcement\",\n",
    "        \"reinforcement\": {\n",
    "            \"grader\": GRADER,\n",
    "            \"response_format\": SCHEMA,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"> Created RFT job {job.id}\")\n",
    "print(job.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
